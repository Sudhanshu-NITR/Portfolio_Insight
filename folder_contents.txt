
--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\.env ---
# LLM provider: ollama | gemini
LLM_PROVIDER=ollama

# Ollama local
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=deepseek-r1:8b
OLLAMA_EMBED_MODEL=nomic-embed-text
EMBED_PROVIDER=hf
HF_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Gemini production
GOOGLE_API_KEY=YOUR_GEMINI_API_KEY
GEMINI_CHAT_MODEL=gemini-1.5-pro
GEMINI_EMBED_MODEL=text-embedding-004

# Market APIs
INDIANAPI_BASE=https://stock.indianapi.in
INDIANAPI_KEY=YOUR_INDIANAPI_KEY

# Cache & vectors
CACHE_TTL_QUOTES=60
CACHE_TTL_CORPORATE=900
CACHE_TTL_FORECASTS=300
VECTOR_DB_DIR=./.chroma

# LLM params
CHAT_TEMPERATURE=0.2
MAX_TOKENS=1500

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\app.py ---
from flask import Flask, jsonify
from flask_cors import CORS
from routes.market_routes import market_bp
from routes.tools_routes import tools_bp
from routes.rag_routes import rag_bp

def create_app():
    app = Flask(__name__)
    CORS(app)
    app.register_blueprint(market_bp)
    app.register_blueprint(tools_bp)
    app.register_blueprint(rag_bp)

    @app.route("/health")
    def health():
        return jsonify({"status":"ok","service":"portfolio-rag-agent"})

    return app

if __name__=="__main__":
    app = create_app()
    app.run(host="0.0.0.0", port=5000, debug=True)

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\config.py ---
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    # LLM provider
    LLM_PROVIDER = os.getenv("LLM_PROVIDER", "ollama").lower()
    OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    OLLAMA_CHAT_MODEL = os.getenv("OLLAMA_CHAT_MODEL", "deepseek-r1:8b")
    OLLAMA_EMBED_MODEL = os.getenv("OLLAMA_EMBED_MODEL", "nomic-embed-text")
    EMBED_PROVIDER = os.getenv("EMBED_PROVIDER", "hf").lower()  # hf | ollama | gemini
    HF_EMBED_MODEL = os.getenv("HF_EMBED_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    GEMINI_CHAT_MODEL = os.getenv("GEMINI_CHAT_MODEL", "gemini-1.5-pro")
    GEMINI_EMBED_MODEL = os.getenv("GEMINI_EMBED_MODEL", "text-embedding-004")

    # Market APIs
    INDIANAPI_BASE = os.getenv("INDIANAPI_BASE", "https://stock.indianapi.in")
    INDIANAPI_KEY = os.getenv("INDIANAPI_KEY")

    # Cache TTLs (seconds)
    CACHE_TTL_QUOTES = int(os.getenv("CACHE_TTL_QUOTES", "60"))
    CACHE_TTL_CORPORATE = int(os.getenv("CACHE_TTL_CORPORATE", "900"))
    CACHE_TTL_FORECASTS = int(os.getenv("CACHE_TTL_FORECASTS", "300"))

    # Vector store
    VECTOR_DB_DIR = os.getenv("VECTOR_DB_DIR", "./.chroma")

    # LLM params
    CHAT_TEMPERATURE = float(os.getenv("CHAT_TEMPERATURE", "0.2"))
    MAX_TOKENS = int(os.getenv("MAX_TOKENS", "1500"))

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\ingestion_manifest.json ---
{
  "manifest": [
    { "type": "pdf", "path": "books/APPLIED_CORPORATE_FINANCE.pdf", "metadata": { "category": "investment_principles", "source": "applied_corporate_finance" } }
  ]
}

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\requirements.txt ---
flask
flask-cors
requests
pandas
yfinance
chromadb
tiktoken
beautifulsoup4
pypdf

langchain
langchain-community
langchain-core
langchain-google-genai
langchain-ollama
langchain-chroma
langchain-huggingface
sentence-transformers
--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\.chroma\chroma.sqlite3 ---
[Could not read file: 'utf-8' codec can't decode byte 0x8b in position 31: invalid start byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\.chroma\7396ba82-4f60-41df-b177-528893973c02\data_level0.bin ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 20: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\.chroma\7396ba82-4f60-41df-b177-528893973c02\header.bin ---
[Could not read file: 'utf-8' codec can't decode byte 0x8c in position 28: invalid start byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\.chroma\7396ba82-4f60-41df-b177-528893973c02\index_metadata.pickle ---
[Could not read file: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\.chroma\7396ba82-4f60-41df-b177-528893973c02\length.bin ---
[Could not read file: 'utf-8' codec can't decode byte 0xfa in position 708: invalid start byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\.chroma\7396ba82-4f60-41df-b177-528893973c02\link_lists.bin ---
[Could not read file: 'utf-8' codec can't decode byte 0xa4 in position 36: invalid start byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\books\Applied_Corporate_Finance.pdf ---
[Could not read file: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\books\Corporate_Finance_An_Introduction.pdf ---
[Could not read file: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\books\Corporate_Finance_for_Long_Term_Value.pdf ---
[Could not read file: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\books\Introduction-to-Financial-Analysis.pdf ---
[Could not read file: 'utf-8' codec can't decode byte 0xc4 in position 10: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\books\Investment_Analysis_and_Portfolio_Management.pdf ---
[Could not read file: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\books\THE-INTELLIGENT-INVESTOR.pdf ---
[Could not read file: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\books\THE-INTELLIGENT-INVESTOR.txt ---
[Could not read file: 'utf-8' codec can't decode byte 0xad in position 4519: invalid start byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\kb\test.txt ---
This is a test paragraph about diversification, compounding, and risk management.

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\agent.py ---
from langchain.agents import initialize_agent, AgentType
from .llm import make_chat_llm
from tools import ALL_TOOLS

SYSTEM = """You are Portfolio Insight, an agentic assistant for Indian markets.
Use tools for live data (quotes, ranges, intraday, corporate actions, forecasts, trending).
Combine with retrieved knowledge to explain what numbers mean.
Include risks and benchmarks; avoid individualized tax/legal advice."""

def build_agent():
    llm = make_chat_llm()
    agent = initialize_agent(
        tools=ALL_TOOLS,
        llm=llm,
        agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
        verbose=False,
        handle_parsing_errors=True,
        agent_kwargs={"system_message": SYSTEM}
    )
    return agent

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\ingestion.py ---
import os, shutil, subprocess
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma  # pip install -U langchain-chroma
from langchain_community.document_loaders import PyPDFLoader, UnstructuredURLLoader, TextLoader
from .llm import make_embedder
from config import Config
from utils.logging_utils import StepTimer

CHUNK_SIZE = 1200
CHUNK_OVERLAP = 150

def load_pdf_resilient(path: str, meta: dict):
    docs = []
    try:
        docs = PyPDFLoader(path).load()
    except Exception:
        docs = []
    if not docs or all((not d.page_content or not d.page_content.strip()) for d in docs):
        if shutil.which("pdftotext"):
            txt_path = path + ".txt"
            try:
                subprocess.run(["pdftotext", "-layout", path, txt_path], check=True)
                tdocs = TextLoader(txt_path, encoding="utf-8").load()
                for d in tdocs:
                    d.metadata.update(meta)
                    d.metadata["note"] = "pdftotext_fallback"
                return tdocs
            except Exception:
                pass
        if shutil.which("ocrmypdf"):
            ocr_path = path + ".ocr.pdf"
            try:
                subprocess.run(["ocrmypdf", "--force-ocr", "--skip-text", path, ocr_path], check=True)
                ocr_docs = PyPDFLoader(ocr_path).load()
                for d in ocr_docs:
                    d.metadata.update(meta)
                    d.metadata["note"] = "ocrmypdf_fallback"
                if ocr_docs:
                    return ocr_docs
            except Exception:
                pass
    for d in docs:
        d.metadata.update(meta)
    return docs

def _abspath(p: str) -> str:
    return p if os.path.isabs(p) else os.path.join(os.getcwd(), p)

def load_docs(manifest: list[dict]):
    docs = []
    for i, item in enumerate(manifest):
        t = item.get("type"); meta = item.get("metadata", {}) or {}
        path = item.get("path"); url = item.get("url")
        if t == "pdf" and path:
            ap = _abspath(path)
            if not os.path.exists(ap):
                print(f"[INGEST] missing PDF: {ap}")
                continue
            loaded = load_pdf_resilient(ap, meta)
            print(f"[INGEST] pdf docs={len(loaded)} file={ap}")
            docs += loaded
        elif t == "url" and url:
            try:
                loader = UnstructuredURLLoader(urls=[url])
                loaded = loader.load()
                for d in loaded: d.metadata.update(meta)
                print(f"[INGEST] url docs={len(loaded)} url={url}")
                docs += loaded
            except Exception as e:
                print(f"[INGEST] url failed {url}: {e}")
        elif t == "text" and path:
            ap = _abspath(path)
            if not os.path.exists(ap):
                print(f"[INGEST] missing text: {ap}")
                continue
            loaded = TextLoader(ap, encoding="utf-8").load()
            for d in loaded: d.metadata.update(meta)
            print(f"[INGEST] text docs={len(loaded)} file={ap}")
            docs += loaded
        else:
            print(f"[INGEST] skipped item[{i}] type={t}")
    return docs

def ingest(manifest: list[dict]):
    tm = StepTimer("INGEST")
    tm.start(f"start; docs={len(manifest)}")
    docs = load_docs(manifest)
    tm.step(f"loaded_docs={len(docs)}")
    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
    tm.step("chunking")
    chunks = splitter.split_documents(docs)
    print(f"[INGEST] total_docs={len(docs)} chunks={len(chunks)}")
    tm.step(f"chunked; chunks={len(chunks)}")
    if not chunks:
        return {"chunks_indexed": 0, "warning": "No text extracted. Provide .txt or install pdftotext/ocrmypdf in PATH."}
    tm.step("embedding init")
    embeddings = make_embedder()
    tm.step("embedding ready")
    tm.step("Chroma open/add")
    db = Chroma(
        collection_name="advisor_kg",
        embedding_function=embeddings,
        persist_directory=Config.VECTOR_DB_DIR  # auto-persistence when this is set
    )
    db.add_documents(chunks)
    return {"chunks_indexed": len(chunks)}

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\llm.py ---
from config import Config

def make_chat_llm():
    if Config.LLM_PROVIDER == "ollama":
        from langchain_ollama import ChatOllama
        return ChatOllama(model=Config.OLLAMA_CHAT_MODEL, base_url=Config.OLLAMA_BASE_URL, temperature=Config.CHAT_TEMPERATURE)
    elif Config.LLM_PROVIDER == "gemini":
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=Config.GEMINI_CHAT_MODEL, google_api_key=Config.GOOGLE_API_KEY, temperature=Config.CHAT_TEMPERATURE)
    raise ValueError("Unsupported LLM_PROVIDER")

def make_embedder():
    if Config.EMBED_PROVIDER == "hf":
        from langchain_huggingface import HuggingFaceEmbeddings  # pip install -U langchain-huggingface
        return HuggingFaceEmbeddings(model_name=Config.HF_EMBED_MODEL, model_kwargs={"device": "cpu"})
    if Config.EMBED_PROVIDER == "ollama":
        from langchain_ollama import OllamaEmbeddings
        return OllamaEmbeddings(model=Config.OLLAMA_EMBED_MODEL, base_url=Config.OLLAMA_BASE_URL)
    if Config.EMBED_PROVIDER == "gemini":
        from langchain_google_genai import GoogleGenerativeAIEmbeddings
        return GoogleGenerativeAIEmbeddings(model=Config.GEMINI_EMBED_MODEL, google_api_key=Config.GOOGLE_API_KEY)
    raise ValueError("Unsupported EMBED_PROVIDER")

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\rag_chain.py ---
from langchain.schema.runnable import RunnablePassthrough
from langchain.prompts import ChatPromptTemplate
from .llm import make_chat_llm
from .retriever import get_retriever

SYSTEM = """You are a professional India-first portfolio assistant.
Use retrieved context for concepts; call tools for current data when needed.
Avoid personalized tax/legal advice; provide risks and benchmark context."""

PROMPT = ChatPromptTemplate.from_messages([
    ("system", SYSTEM),
    ("human", "Question: {question}\n\nContext:\n{context}\n\nAnswer clearly and concisely."),
])

def build_rag_chain():
    retriever = get_retriever()
    llm = make_chat_llm()
    chain = (
        {
            "context": retriever | (lambda docs: "\n\n".join([d.page_content[:1200] for d in docs])),
            "question": RunnablePassthrough()
        }
        | PROMPT
        | llm
    )
    return chain

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\retriever.py ---
from langchain_chroma import Chroma
from .llm import make_embedder
from config import Config

def get_retriever():
    db = Chroma(
        collection_name="advisor_kg",
        embedding_function=make_embedder(),
        persist_directory=Config.VECTOR_DB_DIR
    )
    return db.as_retriever(search_type="mmr", search_kwargs={"k": 6, "fetch_k": 24, "lambda_mult": 0.5})

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\__pycache__\agent.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\__pycache__\ingestion.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\__pycache__\llm.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\__pycache__\rag_chain.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\rag\__pycache__\retriever.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\routes\market_routes.py ---
from flask import Blueprint, request, jsonify
from services.market_data_service import get_quotes, get_price_ranges, get_intraday
from services.corporate_actions_service import get_dividends_and_splits
from services.analyst_service import get_analyst_summary

market_bp = Blueprint("market", __name__)

@market_bp.route("/market/quotes", methods=["POST"])
def market_quotes():
    data = request.get_json(force=True)
    tickers = data.get("tickers", [])
    fields = data.get("fields", None)
    if not tickers: return jsonify({"error":"tickers required"}), 400
    return jsonify(get_quotes(tickers, fields))

@market_bp.route("/market/price_ranges", methods=["POST"])
def market_ranges():
    data = request.get_json(force=True)
    tickers = data.get("tickers", [])
    window_days = data.get("window_days", 252)
    return jsonify(get_price_ranges(tickers, window_days))

@market_bp.route("/market/intraday", methods=["POST"])
def market_intraday():
    data = request.get_json(force=True)
    tickers = data.get("tickers", [])
    interval = data.get("interval", "5m")
    period = data.get("period", "5d")
    return jsonify(get_intraday(tickers, interval, period))

@market_bp.route("/market/corporate-actions", methods=["POST"])
def market_corporate_actions():
    data = request.get_json(force=True)
    tickers = data.get("tickers", [])
    return jsonify(get_dividends_and_splits(tickers))

@market_bp.route("/market/analyst/summary", methods=["POST"])
def market_analyst():
    data = request.get_json(force=True)
    tickers = data.get("tickers", [])
    return jsonify(get_analyst_summary(tickers))

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\routes\rag_routes.py ---
from flask import Blueprint, request, jsonify
from rag.ingestion import ingest
from rag.rag_chain import build_rag_chain
from rag.agent import build_agent
from config import Config

rag_bp = Blueprint("rag", __name__)
_rag_chain = None
_agent = None

def _ensure():
    global _rag_chain, _agent
    if _rag_chain is None:
        _rag_chain = build_rag_chain()
    if _agent is None:
        _agent = build_agent()

@rag_bp.route("/rag/ingest", methods=["POST"])
def rag_ingest():
    payload = request.get_json(force=True)
    manifest = payload.get("manifest") if isinstance(payload, dict) else (payload if isinstance(payload, list) else None)
    if not isinstance(manifest, list) or not manifest:
        return jsonify({"error": "manifest list required"}), 400
    try:
        res = ingest(manifest)
        return jsonify(res)
    except Exception as e:
        return jsonify({"error": str(e)}), 500


from utils.logging_utils import StepTimer

@rag_bp.route("/rag/query", methods=["POST"])
def rag_query():
    _ensure()
    payload = request.get_json(force=True)
    question = payload.get("question","").strip()
    if not question: return jsonify({"error":"question required"}), 400

    tm = StepTimer("RAG_QUERY")
    tm.start(f"q='{question[:80]}...'")

    try:
        # Force a retriever pass timing by invoking the chain with a wrapper.
        ans = _rag_chain.invoke(question)
        tm.step("generated answer")
        content = getattr(ans, "content", None)
        out = {"answer": content if content is not None else str(ans)}
        print("output-> ", out)
        tm.step("response ready")
        return jsonify(out)
    except Exception as e:
        tm.error(f"failed: {e}")
        return jsonify({"error": str(e)}), 500


@rag_bp.route("/rag/agent", methods=["POST"])
def rag_agent():
    _ensure()
    payload = request.get_json(force=True)
    question = payload.get("question","").strip()
    holdings = payload.get("holdings", [])
    if not question: return jsonify({"error":"question required"}), 400

    plan_hint = f"User holdings: {', '.join(holdings)}. Prefer holdings + benchmarks if relevant." if holdings else ""
    tm = StepTimer("AGENT")
    tm.start(f"q='{question[:80]}...' holdings={len(holdings)}")

    try:
        resp = _agent.invoke({"input": f"{plan_hint}\n\n{question}"})
        tm.step("agent output ready")
        return jsonify({"answer": resp.get("output","")})
    except Exception as e:
        tm.error(f"failed: {e}")
        return jsonify({"error": str(e)}), 500

@rag_bp.route("/rag/debug/stats", methods=["GET"])
def rag_stats():
    from langchain_chroma import Chroma  # or community import if you kept it
    from rag.llm import make_embedder
    db = Chroma(collection_name="advisor_kg", embedding_function=make_embedder(), persist_directory=Config.VECTOR_DB_DIR)
    # Chroma doesn’t expose count directly; keep a small local counter if needed during ingest
    return jsonify({"status":"ok"})
--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\routes\tools_routes.py ---
from flask import Blueprint, request, jsonify
from tools.market_tools import tool_get_quotes, tool_get_price_ranges, tool_get_intraday
from tools.analysis_tools import tool_get_corporate_actions, tool_get_trending, tool_get_stock_forecasts
import json

tools_bp = Blueprint("tools", __name__)

@tools_bp.route("/tools/quotes", methods=["POST"])
def tools_quotes():
    payload = request.get_json(force=True)
    return jsonify(json.loads(tool_get_quotes(json.dumps(payload or {}))))

@tools_bp.route("/tools/ranges", methods=["POST"])
def tools_ranges():
    payload = request.get_json(force=True)
    return jsonify(json.loads(tool_get_price_ranges(json.dumps(payload or {}))))

@tools_bp.route("/tools/intraday", methods=["POST"])
def tools_intraday():
    payload = request.get_json(force=True)
    return jsonify(json.loads(tool_get_intraday(json.dumps(payload or {}))))

@tools_bp.route("/tools/corporate-actions", methods=["POST"])
def tools_corporate_actions():
    payload = request.get_json(force=True)
    return jsonify(json.loads(tool_get_corporate_actions(json.dumps(payload or {}))))

@tools_bp.route("/tools/trending", methods=["GET"])
def tools_trending():
    return jsonify(json.loads(tool_get_trending("{}")))

@tools_bp.route("/tools/stock-forecasts", methods=["GET"])
def tools_stock_forecasts():
    p = {
        "stock_id": request.args.get("stock_id",""),
        "measure_code": request.args.get("measure_code","EPS"),
        "period_type": request.args.get("period_type","Annual"),
        "data_type": request.args.get("data_type","Estimates"),
        "age": request.args.get("age","Current")
    }
    return jsonify(json.loads(tool_get_stock_forecasts(json.dumps(p))))

@tools_bp.route("/admin/cache/clear", methods=["POST"])
def admin_cache_clear():
    from utils.cache_utils import clear_cache
    clear_cache()
    return {"status": "cleared"}

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\routes\__init__.py ---

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\routes\__pycache__\market_routes.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\routes\__pycache__\rag_routes.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\routes\__pycache__\tools_routes.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\routes\__pycache__\__init__.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\analyst_service.py ---
import pandas as pd
import yfinance as yf
from utils.ticker_utils import batch_normalize
from utils.cache_utils import get_cached, set_cached

def _df_to_records(df: pd.DataFrame):
    if df is None or df.empty:
        return []
    out = df.reset_index()
    if "Date" in out.columns:
        out["Date"] = pd.to_datetime(out["Date"]).dt.strftime("%Y-%m-%d")
    return out.to_dict(orient="records")

def get_analyst_summary(tickers: list[str]) -> dict:
    params = {"tickers": ",".join(sorted(tickers))}
    cached = get_cached("analyst", params, 600)
    if cached:
        return cached
    out = {}
    for t in tickers:
        nt = batch_normalize([t])[0]
        try:
            tk = yf.Ticker(nt)
            recs = getattr(tk, "recommendations", None)
            trend = getattr(tk, "recommendationTrend", None)
            out[t.upper()] = {
                "symbol": t.upper(),
                "raw_ticker": nt,
                "recommendations": _df_to_records(recs) if isinstance(recs, pd.DataFrame) else [],
                "recommendation_trend": _df_to_records(trend) if isinstance(trend, pd.DataFrame) else [],
                "price_target": {"mean": None, "high": None, "low": None, "num_analysts": None, "note": "Use paid provider for targets"},
                "estimates": {"eps_current_year": None, "eps_next_q": None, "revenue_current_year": None, "revenue_next_q": None, "note": "Use provider for structured estimates"}
            }
        except Exception as e:
            out[t.upper()] = {"symbol": t.upper(), "raw_ticker": nt, "error": str(e)}
    set_cached("analyst", params, out, 600)
    return out

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\corporate_actions_service.py ---
import yfinance as yf
import pandas as pd
from utils.ticker_utils import batch_normalize
from utils.cache_utils import get_cached, set_cached
from config import Config

def _series_to_records(series: pd.Series, value_name: str):
    if series is None or series.empty:
        return []
    df = series.reset_index()
    df.columns = ["date", value_name]
    df["date"] = pd.to_datetime(df["date"]).dt.strftime("%Y-%m-%d")
    if value_name == "dividend":
        df["dividend"] = df["dividend"].astype(float)
    return df.to_dict(orient="records")

def _to_date(ts):
    try:
        if not ts:
            return None
        return pd.to_datetime(int(ts), unit="s").strftime("%Y-%m-%d")
    except Exception:
        return None

def get_dividends_and_splits(tickers: list[str]) -> dict:
    params = {"tickers": ",".join(sorted(tickers))}
    cached = get_cached("corp", params, Config.CACHE_TTL_CORPORATE)
    if cached:
        return cached
    out = {}
    for t in tickers:
        nt = batch_normalize([t])[0]
        try:
            tk = yf.Ticker(nt)
            dividends = _series_to_records(tk.dividends, "dividend")
            splits = _series_to_records(tk.splits, "split_ratio")
            info = {}
            try:
                info = tk.info or {}
            except Exception:
                info = {}
            out[t.upper()] = {
                "symbol": t.upper(),
                "raw_ticker": nt,
                "currency": info.get("currency", "INR"),
                "dividends": dividends,
                "splits": splits,
                "summary": {
                    "ex_dividend_date": _to_date(info.get("exDividendDate")),
                    "dividend_payment_date": _to_date(info.get("dividendDate")),
                    "dividend_yield": float(info.get("dividendYield")) if info.get("dividendYield") is not None else None,
                    "dividend_rate": float(info.get("dividendRate")) if info.get("dividendRate") is not None else None,
                },
                "notes": "Record dates/spinoffs/rights often unavailable via free endpoints."
            }
        except Exception as e:
            out[t.upper()] = {"symbol": t.upper(), "raw_ticker": nt, "error": str(e)}
    set_cached("corp", params, out, Config.CACHE_TTL_CORPORATE)
    return out

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\market_data_service.py ---
import pandas as pd
import yfinance as yf
from utils.ticker_utils import batch_normalize
from utils.cache_utils import get_cached, set_cached
from utils.validation import validate_fields, clamp_window_days, validate_interval, validate_period
from config import Config
from utils.logging_utils import StepTimer

def _extract(df, ticker):
    if df is None or df.empty:
        return pd.DataFrame()
    if isinstance(df.columns, pd.MultiIndex):
        if ticker in df.columns.levels[1]:
            return df.xs(ticker, axis=1, level=1).dropna()
        return pd.DataFrame()
    return df

def get_quotes(tickers: list[str], fields: list[str] | None = None) -> dict:
    tm = StepTimer("QUOTES")
    tm.start(f"tickers={tickers} fields={fields}")
    fields = fields or ["close","previousClose","volume"]
    fields = validate_fields(fields)
    params = {"tickers": ",".join(sorted(tickers)), "fields": ",".join(sorted(fields))}
    cached = get_cached("quotes", params, Config.CACHE_TTL_QUOTES)
    if cached:
        return cached
    norm = batch_normalize(tickers)
    out: dict = {}
    df = yf.download(norm, period="5d", interval="1d", threads=True, auto_adjust=True, progress=False)
    tm.step(f"yf.download done rows={len(df)}")
    mapping = {"close":"Close","previousClose":"Close","open":"Open","high":"High","low":"Low","volume":"Volume"}
    for orig in tickers:
        nt = batch_normalize([orig])[0]
        tdf = _extract(df, nt)
        if tdf.empty:
            out[orig.upper()] = {f: None for f in fields}
            continue
        last = tdf.iloc[-1]
        row = {}
        for f in fields:
            col = mapping.get(f)
            row[f] = float(last.get(col)) if col in tdf.columns else None
        out[orig.upper()] = row
    set_cached("quotes", params, out, Config.CACHE_TTL_QUOTES)
    tm.step("format done")
    return out

def get_price_ranges(tickers: list[str], window_days: int = 252) -> dict:
    window_days = clamp_window_days(window_days)
    params = {"tickers": ",".join(sorted(tickers)), "window": window_days}
    cached = get_cached("ranges", params, Config.CACHE_TTL_QUOTES)
    if cached:
        return cached
    norm = batch_normalize(tickers)
    period = "1y" if window_days > 180 else "6mo"
    df = yf.download(norm, period=period, interval="1d", threads=True, auto_adjust=True, progress=False)
    out = {}
    for orig in tickers:
        nt = batch_normalize([orig])[0]
        tdf = _extract(df, nt)
        if tdf.empty:
            out[orig.upper()] = {"high": None, "low": None, "current": None, "window_days": 0}
            continue
        recent = tdf.tail(window_days)
        out[orig.upper()] = {
            "high": float(recent["High"].max()),
            "low": float(recent["Low"].min()),
            "current": float(recent["Close"].iloc[-1]),
            "window_days": len(recent)
        }
    set_cached("ranges", params, out, Config.CACHE_TTL_QUOTES)
    return out

def get_intraday(tickers: list[str], interval: str = "5m", period: str = "5d") -> dict:
    interval = validate_interval(interval)
    period = validate_period(period)
    params = {"tickers": ",".join(sorted(tickers)), "interval": interval, "period": period}
    cached = get_cached("intraday", params, Config.CACHE_TTL_QUOTES)
    if cached:
        return cached
    norm = batch_normalize(tickers)
    df = yf.download(norm, period=period, interval=interval, threads=True, auto_adjust=True, progress=False)
    out = {}
    for orig in tickers:
        nt = batch_normalize([orig])[0]
        tdf = _extract(df, nt)
        out[orig.upper()] = {
            "interval": interval, "period": period,
            "data": tdf.reset_index().to_dict(orient="records")
        }
    set_cached("intraday", params, out, Config.CACHE_TTL_QUOTES)
    return out

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\stock_forecasts_service.py ---
import requests
from enum import Enum
from datetime import datetime
from config import Config

class PeriodType(str, Enum):
    ANNUAL = "Annual"
    INTERIM = "Interim"

class DataType(str, Enum):
    ACTUALS = "Actuals"
    ESTIMATES = "Estimates"

class DataAge(str, Enum):
    ONE_WEEK_AGO = "OneWeekAgo"
    THIRTY_DAYS_AGO = "ThirtyDaysAgo"
    SIXTY_DAYS_AGO = "SixtyDaysAgo"
    NINETY_DAYS_AGO = "NinetyDaysAgo"
    CURRENT = "Current"

class MeasureCode(str, Enum):
    EPS="EPS"; CPS="CPS"; CPX="CPX"; DPS="DPS"; EBI="EBI"; EBT="EBT"; GPS="GPS"; GRM="GRM"
    NAV="NAV"; NDT="NDT"; NET="NET"; PRE="PRE"; ROA="ROA"; ROE="ROE"; SAL="SAL"

def get_stock_forecasts(stock_id: str, measure_code: str, period_type: str, data_type: str, age: str):
    if not stock_id:
        raise ValueError("stock_id is required")
    if measure_code not in [e.value for e in MeasureCode]: raise ValueError("invalid measure_code")
    if period_type not in [e.value for e in PeriodType]: raise ValueError("invalid period_type")
    if data_type not in [e.value for e in DataType]: raise ValueError("invalid data_type")
    if age not in [e.value for e in DataAge]: raise ValueError("invalid age")
    url = f"{Config.INDIANAPI_BASE}/stock_forecasts"
    headers = {"X-Api-Key": Config.INDIANAPI_KEY}
    params = {"stock_id": stock_id, "measure_code": measure_code, "period_type": period_type, "data_type": data_type, "age": age}
    r = requests.get(url, headers=headers, params=params, timeout=20)
    if r.status_code == 404:
        return {"status": 404, "message": "No forecasts found"}
    r.raise_for_status()
    data = r.json()
    return {"query": params, "data": data.get("data", data), "meta": {"source":"stock.indianapi.in", "retrieved_at": datetime.utcnow().isoformat()+"Z"}}

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\trending_service.py ---
import requests
from config import Config
from utils.cache_utils import get_cached, set_cached

def _strip_nulls(obj):
    if isinstance(obj, dict):
        return {k: _strip_nulls(v) for k, v in obj.items() if v not in [None, '', [], {}]}
    if isinstance(obj, list):
        return [_strip_nulls(x) for x in obj if x not in [None, '', [], {}]]
    return obj

def get_trending(exchange: str = "NSE", limit: int = 3) -> dict:
    params = {"exchange": exchange, "limit": limit}
    cached = get_cached("trending", params, 300)
    if cached:
        return cached
    url = f"{Config.INDIANAPI_BASE}/trending"
    headers = {"X-Api-Key": Config.INDIANAPI_KEY}
    r = requests.get(url, headers=headers, timeout=15)
    r.raise_for_status()
    data = r.json()
    if "trending_stocks" in data:
        data["trending_stocks"]["top_gainers"] = data["trending_stocks"].get("top_gainers", [])[:limit]
        data["trending_stocks"]["top_losers"] = data["trending_stocks"].get("top_losers", [])[:limit]
    cleaned = _strip_nulls(data)
    set_cached("trending", params, cleaned, 300)
    return cleaned

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\__pycache__\analyst_service.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\__pycache__\corporate_actions_service.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\__pycache__\market_data_service.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\__pycache__\stock_forecasts_service.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\services\__pycache__\trending_service.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\tools\analysis_tools.py ---
import json
from services.corporate_actions_service import get_dividends_and_splits as _corp
from services.trending_service import get_trending as _trend
from services.stock_forecasts_service import get_stock_forecasts as _fore

def tool_get_corporate_actions(params_json: str) -> str:
    p = json.loads(params_json or "{}")
    data = _corp(p.get("tickers", []))
    if not p.get("include_dividends", True):
        for k in data:
            data[k].pop("dividends", None)
            data[k].pop("summary", None)
    if not p.get("include_splits", True):
        for k in data:
            data[k].pop("splits", None)
    return json.dumps(data)

def tool_get_trending(params_json: str) -> str:
    p = json.loads(params_json or "{}")
    return json.dumps(_trend(p.get("exchange", "NSE"), p.get("limit", 3)))

def tool_get_stock_forecasts(params_json: str) -> str:
    p = json.loads(params_json or "{}")
    return json.dumps(_fore(
        p.get("stock_id",""),
        p.get("measure_code","EPS"),
        p.get("period_type","Annual"),
        p.get("data_type","Estimates"),
        p.get("age","Current"),
    ))

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\tools\market_tools.py ---
import json
from services.market_data_service import get_quotes as _q, get_price_ranges as _r, get_intraday as _i

def tool_get_quotes(params_json: str) -> str:
    p = json.loads(params_json or "{}")
    return json.dumps(_q(p.get("tickers", []), p.get("fields")))

def tool_get_price_ranges(params_json: str) -> str:
    p = json.loads(params_json or "{}")
    return json.dumps(_r(p.get("tickers", []), p.get("window_days", 252)))

def tool_get_intraday(params_json: str) -> str:
    p = json.loads(params_json or "{}")
    return json.dumps(_i(p.get("tickers", []), p.get("interval", "5m"), p.get("period", "5d")))

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\tools\schemas.py ---
from pydantic import BaseModel, Field
from typing import List, Optional

class QuotesInput(BaseModel):
    tickers: List[str] = Field(..., description="Symbols like ['RELIANCE','^NSEI']")
    fields: Optional[List[str]] = Field(default=None, description="Fields like ['close','previousClose','volume']")

class RangesInput(BaseModel):
    tickers: List[str]
    window_days: Optional[int] = 252

class IntradayInput(BaseModel):
    tickers: List[str]
    interval: Optional[str] = "5m"
    period: Optional[str] = "5d"

class CorporateInput(BaseModel):
    tickers: List[str]
    include_dividends: Optional[bool] = True
    include_splits: Optional[bool] = True

class TrendingInput(BaseModel):
    exchange: Optional[str] = "NSE"
    limit: Optional[int] = 3

class ForecastsInput(BaseModel):
    stock_id: str
    measure_code: str = "EPS"
    period_type: str = "Annual"
    data_type: str = "Estimates"
    age: str = "Current"

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\tools\__init__.py ---
from langchain.tools import tool
import json
from .market_tools import tool_get_quotes, tool_get_price_ranges, tool_get_intraday
from .analysis_tools import tool_get_corporate_actions, tool_get_trending, tool_get_stock_forecasts
from .schemas import QuotesInput, RangesInput, IntradayInput, CorporateInput, TrendingInput, ForecastsInput

@tool("get_current_quotes", args_schema=QuotesInput)
def get_current_quotes(tickers: list[str], fields: list[str] | None = None) -> str:
    """Get current stock quotes for given tickers."""
    return tool_get_quotes(json.dumps({"tickers": tickers, "fields": fields}))

@tool("get_price_ranges", args_schema=RangesInput)
def get_price_ranges(tickers: list[str], window_days: int = 252) -> str:
    """Get high/low/current for a window of days."""
    return tool_get_price_ranges(json.dumps({"tickers": tickers, "window_days": window_days}))

@tool("get_intraday_data", args_schema=IntradayInput)
def get_intraday_data(tickers: list[str], interval: str = "5m", period: str = "5d") -> str:
    """Get intraday candles for tickers."""
    return tool_get_intraday(json.dumps({"tickers": tickers, "interval": interval, "period": period}))

@tool("get_corporate_actions", args_schema=CorporateInput)
def get_corporate_actions(tickers: list[str], include_dividends: bool = True, include_splits: bool = True) -> str:
    """Get dividends and splits for tickers."""
    return tool_get_corporate_actions(json.dumps({"tickers": tickers, "include_dividends": include_dividends, "include_splits": include_splits}))

@tool("get_trending_stocks", args_schema=TrendingInput)
def get_trending_stocks(exchange: str = "NSE", limit: int = 3) -> str:
    """Get top gainers/losers for an exchange."""
    return tool_get_trending(json.dumps({"exchange": exchange, "limit": limit}))

@tool("get_stock_forecasts", args_schema=ForecastsInput)
def get_stock_forecasts(stock_id: str, measure_code: str = "EPS", period_type: str = "Annual", data_type: str = "Estimates", age: str = "Current") -> str:
    """Get forecasts/estimates for a stock."""
    return tool_get_stock_forecasts(json.dumps({
        "stock_id": stock_id,
        "measure_code": measure_code,
        "period_type": period_type,
        "data_type": data_type,
        "age": age
    }))

ALL_TOOLS = [
    get_current_quotes,
    get_price_ranges,
    get_intraday_data,
    get_corporate_actions,
    get_trending_stocks,
    get_stock_forecasts,
]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\tools\__pycache__\analysis_tools.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\tools\__pycache__\market_tools.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\tools\__pycache__\schemas.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\tools\__pycache__\__init__.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\utils\cache_utils.py ---
import time
from typing import Any, Optional

_cache: dict[str, dict] = {}

def _key(prefix: str, params: dict) -> str:
    items = sorted(params.items())
    return prefix + ":" + "&".join([f"{k}={v}" for k, v in items])

def get_cached(prefix: str, params: dict, ttl: int) -> Optional[Any]:
    key = _key(prefix, params)
    entry = _cache.get(key)
    if not entry:
        return None
    if time.time() - entry["ts"] < ttl:
        return entry["data"]
    return None

def set_cached(prefix: str, params: dict, data: Any, ttl: int):
    key = _key(prefix, params)
    _cache[key] = {"ts": time.time(), "ttl": ttl, "data": data}

def clear_cache(prefix: str | None = None):
    if not prefix:
        _cache.clear()
        return
    for k in list(_cache.keys()):
        if k.startswith(prefix + ":"):
            _cache.pop(k, None)

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\utils\logging_utils.py ---
import time, uuid

class StepTimer:
    def __init__(self, label: str, req_id: str | None = None):
        self.label = label
        self.req_id = req_id or str(uuid.uuid4())[:8]
        self.t0 = None
    def start(self, msg: str):
        self.t0 = time.time()
        print(f"[{self.req_id}] ⏳ {self.label} - {msg}")
    def step(self, msg: str):
        if self.t0 is None: self.t0 = time.time()
        el = (time.time() - self.t0) * 1000
        print(f"[{self.req_id}] ✅ {self.label} - {msg} ({el:.0f} ms)")
    def error(self, msg: str):
        el = (time.time() - self.t0) * 1000 if self.t0 else 0
        print(f"[{self.req_id}] ❌ {self.label} - {msg} ({el:.0f} ms)")

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\utils\ticker_utils.py ---
def normalize_ticker(ticker: str) -> str:
    t = ticker.strip().upper()
    if t.startswith("^"):
        return t
    if "." in t:
        return t
    return f"{t}.NS"

def batch_normalize(tickers: list[str]) -> list[str]:
    return list(dict.fromkeys([normalize_ticker(t) for t in tickers]))

def add_benchmarks(tickers: list[str]) -> list[str]:
    out = batch_normalize(tickers)
    for idx in ["^NSEI", "^BSESN"]:
        if idx not in out:
            out.append(idx)
    return out

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\utils\validation.py ---
ALLOWED_FIELDS = {"close","previousClose","open","high","low","volume"}
ALLOWED_INTERVALS = {"1m","5m","15m","1d"}
ALLOWED_PERIODS = {"1d","5d","1mo","6mo","1y"}

def validate_fields(fields: list[str]) -> list[str]:
    return [f for f in fields if f in ALLOWED_FIELDS]

def clamp_window_days(n: int) -> int:
    try:
        n = int(n)
    except Exception:
        return 252
    return max(1, min(1095, n))

def validate_interval(i: str) -> str:
    return i if i in ALLOWED_INTERVALS else "5m"

def validate_period(p: str) -> str:
    return p if p in ALLOWED_PERIODS else "5d"

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\utils\__pycache__\cache_utils.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\utils\__pycache__\logging_utils.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\utils\__pycache__\ticker_utils.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\utils\__pycache__\validation.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]

--- D:\\Portfolio_Insight\\Project\\portfolio-insight\\flask-backend\__pycache__\config.cpython-313.pyc ---
[Could not read file: 'utf-8' codec can't decode byte 0xf3 in position 0: invalid continuation byte]
